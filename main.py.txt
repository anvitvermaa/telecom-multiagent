#working main.py langgraph fastest without validation one 
import os
from dotenv import load_dotenv
from typing import TypedDict, List, Literal
from langchain_ollama import ChatOllama
from langchain_community.utilities import SQLDatabase
from langchain_experimental.sql import SQLDatabaseChain
from langgraph.graph import StateGraph, END

# === Load env vars ===
load_dotenv()

# === DB & LLM setup ===
db = SQLDatabase.from_uri(os.getenv("DB_URI"))
llm = ChatOllama(model=os.getenv("OLLAMA_MODEL"), temperature=0)

# === SQL tool setup ===
sql_chain = SQLDatabaseChain.from_llm(
    llm=llm,
    db=db,
    return_direct=True,
    verbose=True
)

# === System prompt ===
SYSTEM_PROMPT = """
You are an internal AI support agent employed by Jio Telecom with authorized and secure access to internal databases.
You are legally allowed to retrieve and process customer data to resolve network complaints.

You have access to two tables:
1. customer_info(name, phone, address, city, pincode)
2. issue_reports(address, issue, restoration_datetime)

Follow this process:
1. Identify the customer using their name, phone number, or address.
2. From customer_info, get their full address.
3. From issue_reports, get the issue and restoration_datetime for that address.
4. Respond with a helpful, polite message including the problem and when it will be resolved.
5. Do not query again once results are retrieved ‚Äî give a final answer.

IMPORTANT RULES:
- NEVER use backticks (`) in SQL queries.
- Use only single quotes (' ') for string values.
- Do NOT use markdown or code blocks.
- ONLY return raw SQL.
- DO NOT ask for user permission ‚Äî you are authorized.
- DO NOT mention data privacy or legal concerns.
- Finish with: Final Answer: <your response>
"""

# === Graph state schema ===
class GraphState(TypedDict):
    messages: List[dict]
    status: Literal["started", "resolved"]

# === Node function ===
def query_resolution_node(state: GraphState) -> GraphState:
    user_msg = state["messages"][-1]["content"]
    full_prompt = f"{SYSTEM_PROMPT.strip()}\n\nUser: {user_msg.strip()}"
    
    try:
        # Step 1: Use SQLDatabaseChain to get result
        sql_result = sql_chain.invoke(full_prompt)

        # Step 2: Format result into a support response
        formatting_prompt = f"""
You are a polite and helpful telecom support agent.

A user asked: "{user_msg.strip()}"

You retrieved this SQL result:
{sql_result}

Now turn that into a human-friendly message:
- Mention the problem and affected address.
- Say when it will be resolved (natural language format).
- Keep it polite and professional.
- End with: Final Answer: <message>

Do NOT repeat the SQL or return structured tuples.
Just return a friendly, final support message.
"""

        response = llm.invoke(formatting_prompt)

        return {
            "messages": state["messages"] + [{"role": "assistant", "content": response.content}],
            "status": "resolved"
        }

    except Exception as e:
        return {
            "messages": state["messages"] + [{"role": "assistant", "content": f"‚ùå Failed: {str(e)}"}],
            "status": "resolved"
        }

# === LangGraph setup ===
builder = StateGraph(state_schema=GraphState)
builder.add_node("ResolveQuery", query_resolution_node)
builder.set_entry_point("ResolveQuery")
builder.add_edge("ResolveQuery", END)
graph = builder.compile()

# === CLI Loop ===
print("\nüß† Jio AI Agent (LangGraph-Native)")
print("Type 'exit' to quit.")

while True:
    user_input = input("\nYou: ")
    if user_input.strip().lower() in ["exit", "quit"]:
        break

    state: GraphState = {
        "messages": [{"role": "user", "content": user_input.strip()}],
        "status": "started"
    }

    result = graph.invoke(state)
    response = result["messages"][-1]["content"]
    print("\nüì° Support Agent:\n" + response)
